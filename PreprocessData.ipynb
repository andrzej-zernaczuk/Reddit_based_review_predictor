{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e501560f-da90-4ba9-bc9d-8c4684cd76fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:05.695671Z",
     "iopub.status.busy": "2021-06-20T23:33:05.695117Z",
     "iopub.status.idle": "2021-06-20T23:33:05.705518Z",
     "shell.execute_reply": "2021-06-20T23:33:05.703835Z",
     "shell.execute_reply.started": "2021-06-20T23:33:05.695613Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_text as tf_text\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, InputLayer, GlobalMaxPool1D, Dropout, Conv1D, MaxPool1D, Flatten, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b8a51a-3cc6-4bd3-b55a-c7f18cfce0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:06.031864Z",
     "iopub.status.busy": "2021-06-20T23:33:06.031133Z",
     "iopub.status.idle": "2021-06-20T23:33:06.038795Z",
     "shell.execute_reply": "2021-06-20T23:33:06.036964Z",
     "shell.execute_reply.started": "2021-06-20T23:33:06.031814Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10 \n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6da2a9ae-d17d-403d-8d74-6778c6aece4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:06.348909Z",
     "iopub.status.busy": "2021-06-20T23:33:06.346288Z",
     "iopub.status.idle": "2021-06-20T23:33:06.364979Z",
     "shell.execute_reply": "2021-06-20T23:33:06.363363Z",
     "shell.execute_reply.started": "2021-06-20T23:33:06.348578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def first_data_prep():\n",
    "    data = pd.read_csv('Data/twitter_data.csv', \n",
    "                      encoding='latin-1', names=['sentiment', 'id', 'date', 'flag', 'user',\n",
    "                                                'text'])\n",
    "    data['sentiment'].replace(4, 1, inplace=True)\n",
    "    data = data.sample(frac=1).reset_index(drop=True).copy()\n",
    "    data['text'] = data['text'].str.lower()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bcd13b7-0843-4b32-ad1a-b160ac329811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:06.586331Z",
     "iopub.status.busy": "2021-06-20T23:33:06.585845Z",
     "iopub.status.idle": "2021-06-20T23:33:06.593970Z",
     "shell.execute_reply": "2021-06-20T23:33:06.592134Z",
     "shell.execute_reply.started": "2021-06-20T23:33:06.586278Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_nicknames(row):\n",
    "    # Prepare list of words\n",
    "    words = row.split()\n",
    "    # Remove nicknames\n",
    "    for word in words:\n",
    "        if word[0] == '@':\n",
    "            words.remove(word)\n",
    "    # Return string \n",
    "    return ' '.join(word for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bdfc756-2ac8-49e5-8d79-f3c7387ba9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:06.843825Z",
     "iopub.status.busy": "2021-06-20T23:33:06.843131Z",
     "iopub.status.idle": "2021-06-20T23:33:06.852045Z",
     "shell.execute_reply": "2021-06-20T23:33:06.850239Z",
     "shell.execute_reply.started": "2021-06-20T23:33:06.843760Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_split(df, size):\n",
    "    # Split dataset into smaller one \n",
    "    col_list = list(df.columns)\n",
    "    # Drop target column name\n",
    "    col_list.pop(0)\n",
    "    x_train, x_valid = train_test_split(\n",
    "    df, random_state=1, stratify=df['sentiment'], test_size=size)\n",
    "    # Prepare new indexes \n",
    "    x_valid.reset_index(drop=True, inplace=True)\n",
    "    return x_valid \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cda9969-ca0d-43a6-9f89-1342dcde9332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:07.267818Z",
     "iopub.status.busy": "2021-06-20T23:33:07.267350Z",
     "iopub.status.idle": "2021-06-20T23:33:07.276076Z",
     "shell.execute_reply": "2021-06-20T23:33:07.274525Z",
     "shell.execute_reply.started": "2021-06-20T23:33:07.267772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_with_space(text):\n",
    "    # Replace new rows with space \n",
    "    text = text.replace('\\n', \" \").replace(\"\\r\", \" \")\n",
    "    # Create list of all not needed chars \n",
    "    punc_list = '!\"@#$%^&*()+_-.<>?/:;[]{}|\\~'\n",
    "    # Make transformation with dict that contains punc_list chars\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    # Apply transformation\n",
    "    text = text.translate(t)\n",
    "    # Replace single quote with empty char\n",
    "    t = text.maketrans(dict.fromkeys(\"'`\"))\n",
    "    text.translate(t)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bc9cf7e8-aeb0-4998-b220-4ed427c348e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:07.547488Z",
     "iopub.status.busy": "2021-06-20T23:33:07.547022Z",
     "iopub.status.idle": "2021-06-20T23:33:07.565728Z",
     "shell.execute_reply": "2021-06-20T23:33:07.555608Z",
     "shell.execute_reply.started": "2021-06-20T23:33:07.547435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    # Prepare set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords from the text\n",
    "    filtered_text = [word for word in text.split() if not word in stop_words]\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f7a94e9-484f-468d-9576-2f1a35aa86bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:07.945790Z",
     "iopub.status.busy": "2021-06-20T23:33:07.944939Z",
     "iopub.status.idle": "2021-06-20T23:33:07.973180Z",
     "shell.execute_reply": "2021-06-20T23:33:07.971242Z",
     "shell.execute_reply.started": "2021-06-20T23:33:07.945705Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(): \n",
    "    data1 = first_data_prep()\n",
    "    data = stratified_split(data1, 0.1)\n",
    "    # Apply replace func that replace chars with spaces\n",
    "    data.loc[:, 'text'] = data['text'].apply(lambda x: replace_with_space(x))\n",
    "    # Apply func that removes stop words\n",
    "    data.loc[:, 'text'] = data['text'].apply(lambda x: remove_stop_words(x))\n",
    "    w2v_model = gensim.models.word2vec.Word2Vec(vector_size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)\n",
    "    \n",
    "    documents = data.text\n",
    "    w2v_model.build_vocab(documents)\n",
    "    \n",
    "    tok = tf.keras.preprocessing.text.Tokenizer(num_words=100000)\n",
    "    # Updates internal vocabulary based on a list of texts \n",
    "    tok.fit_on_texts(list(data['text']))\n",
    "    # Transforms each text in texts to a sequence of integers.\n",
    "    seq = tok.texts_to_sequences(list(data['text']))\n",
    "    # Pad sequences to make them same lenght \n",
    "    tf_ready = tf.keras.preprocessing.sequence.pad_sequences(seq)\n",
    "    \n",
    "    words = w2v_model.wv.index_to_key\n",
    "    vocab_size = len(tok.word_index) + 1\n",
    "    \n",
    "    w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "    for word, i in tok.word_index.items():\n",
    "        if word in w2v_model.wv:\n",
    "            embedding_matrix[i] = w2v_model.wv[word]\n",
    "    embedding_layer = Embedding(vocab_size, W2V_SIZE,\n",
    "                            weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)\n",
    "    \n",
    "    tf_df = pd.DataFrame(tf_ready)\n",
    "    tf_df['sentiment'] = data['sentiment']\n",
    "    \n",
    "    return tf_df, tok, embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1f96670-c18b-4736-b2f2-f3b7bcc9cfd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:08.535621Z",
     "iopub.status.busy": "2021-06-20T23:33:08.535167Z",
     "iopub.status.idle": "2021-06-20T23:33:08.543133Z",
     "shell.execute_reply": "2021-06-20T23:33:08.541114Z",
     "shell.execute_reply.started": "2021-06-20T23:33:08.535578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pickle_data():\n",
    "    with open('tok.pkl', 'wb') as f:\n",
    "        pickle.dump(tok, f)\n",
    "        \n",
    "    with open('embedding.pkl', 'wb') as f:\n",
    "        pickle.dump(embedding_layer, f)\n",
    "        \n",
    "    \n",
    "    with open('tf_df.pkl', 'wb') as f:\n",
    "        pickle.dump(tf_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9231c5e3-8e3a-4d12-82cc-77a522af74d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:08.895955Z",
     "iopub.status.busy": "2021-06-20T23:33:08.895366Z",
     "iopub.status.idle": "2021-06-20T23:33:08.916609Z",
     "shell.execute_reply": "2021-06-20T23:33:08.914571Z",
     "shell.execute_reply.started": "2021-06-20T23:33:08.895890Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def configure_cnn(data,\n",
    "                embedding,\n",
    "                layers=None, \n",
    "                dropout_rate=0,\n",
    "                kernel_size=10,\n",
    "                stride=10,\n",
    "                pool_size=2,\n",
    "                optimizer='Adam',\n",
    "                loss='binary_crossentropy',\n",
    "                 kernel_initializer='lecun_normal',\n",
    "                 kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "                ):\n",
    "    \"\"\" Layers argument shape:\n",
    "    [[number of nodes, activate function], \n",
    "    [number of nodes, activate function],\n",
    "    ...]\n",
    "    \n",
    "    \"\"\"\n",
    "    input_len = data.shape[1] - 1 \n",
    "    model = Sequential()\n",
    "    model.add(embedding)\n",
    "    model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPool1D(3))\n",
    "    model.add(Conv1D(64, 3, activation='relu'))\n",
    "    model.add(MaxPool1D(pool_size=3))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    if layers != None:\n",
    "        for node in layers[1:]:\n",
    "            model.add(Dense(node[0], activation=node[1], kernel_initializer=kernel_initializer, \n",
    "                            kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, \n",
    "                    kernel_regularizer=kernel_regularizer))\n",
    "    \n",
    "    model.compile(loss=loss, \n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a7c6a7a4-0408-43f8-a578-f64a7596ef81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:09.454591Z",
     "iopub.status.busy": "2021-06-20T23:33:09.453956Z",
     "iopub.status.idle": "2021-06-20T23:33:09.468363Z",
     "shell.execute_reply": "2021-06-20T23:33:09.466395Z",
     "shell.execute_reply.started": "2021-06-20T23:33:09.454511Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def configure_rnn(data,\n",
    "                embedding,\n",
    "                layers=None, \n",
    "                dropout_rate=0,\n",
    "                kernel_size=10,\n",
    "                stride=10,\n",
    "                pool_size=2,\n",
    "                optimizer='Adam',\n",
    "                loss='binary_crossentropy',\n",
    "                 kernel_initializer='lecun_normal',\n",
    "                 kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "                ):\n",
    "    \"\"\" Layers argument shape:\n",
    "    [[number of nodes, activate function], \n",
    "    [number of nodes, activate function],\n",
    "    ...]\n",
    "    \n",
    "    \"\"\"\n",
    "    input_len = data.shape[1] - 1 \n",
    "    model = Sequential()\n",
    "    model.add(embedding)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))    \n",
    "\n",
    "    if layers != None:\n",
    "        for node in layers[1:]:\n",
    "            model.add(Dense(node[0], activation=node[1], kernel_initializer=kernel_initializer, \n",
    "                            kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, \n",
    "                    kernel_regularizer=kernel_regularizer))\n",
    "    \n",
    "    model.compile(loss=loss, \n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46667883-b0fc-4dac-a86f-757c2285ea95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T22:41:38.241065Z",
     "iopub.status.busy": "2021-06-20T22:41:38.240621Z",
     "iopub.status.idle": "2021-06-20T22:43:42.077692Z",
     "shell.execute_reply": "2021-06-20T22:43:42.076353Z",
     "shell.execute_reply.started": "2021-06-20T22:41:38.241023Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakub/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1745: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(ilocs[0], value)\n"
     ]
    }
   ],
   "source": [
    "tf_df, tok, embedding_layer = tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a2dc25a-9ada-4e71-81f9-f0a95d56de7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T22:44:13.058689Z",
     "iopub.status.busy": "2021-06-20T22:44:13.058229Z",
     "iopub.status.idle": "2021-06-20T22:44:14.312688Z",
     "shell.execute_reply": "2021-06-20T22:44:14.311356Z",
     "shell.execute_reply.started": "2021-06-20T22:44:13.058645Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = configure_cnn(tf_df, embedding_layer)\n",
    "model_rnn = configure_rnn(tf_df, embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2648268-6ef0-42bd-b48d-e46301c18b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:27:08.079019Z",
     "iopub.status.busy": "2021-06-17T18:27:08.078704Z",
     "iopub.status.idle": "2021-06-17T18:27:08.311098Z",
     "shell.execute_reply": "2021-06-17T18:27:08.310094Z",
     "shell.execute_reply.started": "2021-06-17T18:27:08.078992Z"
    }
   },
   "outputs": [],
   "source": [
    "features = tf_df.columns.tolist()\n",
    "features.remove('sentiment')\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_df[features], tf_df['sentiment'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0686d7b-3c49-4c52-adf2-08005a28fea9",
   "metadata": {},
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "201f3d48-f00c-4761-a7ad-36a25d277787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T22:44:19.317320Z",
     "iopub.status.busy": "2021-06-20T22:44:19.316700Z",
     "iopub.status.idle": "2021-06-20T22:44:19.334390Z",
     "shell.execute_reply": "2021-06-20T22:44:19.332834Z",
     "shell.execute_reply.started": "2021-06-20T22:44:19.317257Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 300)          44412300  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 300, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 30, 128)           24704     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 44,473,345\n",
      "Trainable params: 61,045\n",
      "Non-trainable params: 44,412,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2eff5d4-e725-4a75-92dc-75761d9e616b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T22:44:21.563204Z",
     "iopub.status.busy": "2021-06-20T22:44:21.561563Z",
     "iopub.status.idle": "2021-06-20T22:44:21.593456Z",
     "shell.execute_reply": "2021-06-20T22:44:21.591341Z",
     "shell.execute_reply.started": "2021-06-20T22:44:21.563048Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 300)          44412300  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 44,572,801\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 44,412,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b941d-575a-4cfe-be12-27df523677c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=EPOCHS, verbose=1,\n",
    "         validation_data=(X_test, y_test), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cba050-8fb9-43bd-8d9a-8803f4d95f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a40f6c03-41d5-4775-b454-f1d85b5ee012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:27:18.473119Z",
     "iopub.status.busy": "2021-06-17T18:27:18.472803Z",
     "iopub.status.idle": "2021-06-17T19:36:32.013144Z",
     "shell.execute_reply": "2021-06-17T19:36:32.011988Z",
     "shell.execute_reply.started": "2021-06-17T18:27:18.473088Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.7180WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "524/524 [==============================] - 520s 990ms/step - loss: 0.5563 - accuracy: 0.7181 - val_loss: 0.4796 - val_accuracy: 0.7726\n",
      "Epoch 2/8\n",
      "524/524 [==============================] - 519s 991ms/step - loss: 0.4991 - accuracy: 0.7592 - val_loss: 0.4727 - val_accuracy: 0.7778\n",
      "Epoch 3/8\n",
      "524/524 [==============================] - 520s 993ms/step - loss: 0.4886 - accuracy: 0.7665 - val_loss: 0.4649 - val_accuracy: 0.7829\n",
      "Epoch 4/8\n",
      "524/524 [==============================] - 519s 990ms/step - loss: 0.4818 - accuracy: 0.7701 - val_loss: 0.4647 - val_accuracy: 0.7841\n",
      "Epoch 5/8\n",
      "524/524 [==============================] - 517s 987ms/step - loss: 0.4786 - accuracy: 0.7728 - val_loss: 0.4645 - val_accuracy: 0.7841\n",
      "Epoch 6/8\n",
      "524/524 [==============================] - 518s 990ms/step - loss: 0.4762 - accuracy: 0.7733 - val_loss: 0.4586 - val_accuracy: 0.7867\n",
      "Epoch 7/8\n",
      "524/524 [==============================] - 520s 992ms/step - loss: 0.4736 - accuracy: 0.7759 - val_loss: 0.4588 - val_accuracy: 0.7873\n",
      "Epoch 8/8\n",
      "524/524 [==============================] - 519s 991ms/step - loss: 0.4723 - accuracy: 0.7763 - val_loss: 0.4580 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f14df780fa0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train, epochs=EPOCHS, verbose=1,\n",
    "         validation_data=(X_test, y_test), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "161157e0-6775-4415-b814-2de413be67c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T19:36:32.015581Z",
     "iopub.status.busy": "2021-06-17T19:36:32.015146Z",
     "iopub.status.idle": "2021-06-17T19:36:43.344731Z",
     "shell.execute_reply": "2021-06-17T19:36:43.341604Z",
     "shell.execute_reply.started": "2021-06-17T19:36:32.015539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: rnn/assets\n"
     ]
    }
   ],
   "source": [
    "model_rnn.save('rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b1fcfa1-39be-4eeb-a1d4-c8cf0f0cd505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:13.307715Z",
     "iopub.status.busy": "2021-06-20T23:33:13.306230Z",
     "iopub.status.idle": "2021-06-20T23:33:13.316503Z",
     "shell.execute_reply": "2021-06-20T23:33:13.314429Z",
     "shell.execute_reply.started": "2021-06-20T23:33:13.307649Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_int(row):\n",
    "    try: \n",
    "        return float(row)\n",
    "    except:\n",
    "        return np.NaN\n",
    "\n",
    "def prepare_reviews(row):\n",
    "    try:\n",
    "        if int(row) < 10:\n",
    "            return row * 10\n",
    "        elif int(row) > 100:\n",
    "            return int(row)/10 \n",
    "        else:\n",
    "            return int(row)\n",
    "    except:\n",
    "        return np.NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "91282c14-b4ec-4f9c-99dc-24a5f790fa0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:39:26.078283Z",
     "iopub.status.busy": "2021-06-20T23:39:26.077782Z",
     "iopub.status.idle": "2021-06-20T23:39:26.087949Z",
     "shell.execute_reply": "2021-06-20T23:39:26.085925Z",
     "shell.execute_reply.started": "2021-06-20T23:39:26.078237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_300_imdb():\n",
    "    names = pd.read_csv('Data/IMDb movies.csv')\n",
    "    ratings = pd.read_csv('Data/IMDb ratings.csv')\n",
    "    full = names.merge(ratings, on='imdb_title_id')\n",
    "    full.loc[:, 'year'] = full['year'].apply(lambda x: to_int(x))\n",
    "    last_data = full.loc[(full['country'].isin(['USA', 'Canada'])) & (full['year'] > 2015)]\n",
    "    last_data.loc[:, 'reviews_from_users'] = last_data['reviews_from_users'].apply(lambda x: prepare_reviews(x))\n",
    "    df_ready = last_data[['original_title', 'reviews_from_users']]\n",
    "    df_ready.to_csv('Data/titles_with_reviews.csv')\n",
    "    df_ready['preds'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56f82bea-d36e-4e2b-823e-47fb5ecaddb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:33:16.422730Z",
     "iopub.status.busy": "2021-06-20T23:33:16.421918Z",
     "iopub.status.idle": "2021-06-20T23:33:16.433555Z",
     "shell.execute_reply": "2021-06-20T23:33:16.431628Z",
     "shell.execute_reply.started": "2021-06-20T23:33:16.422605Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    data = pd.read_csv('preds.csv')\n",
    "    data = data.dropna(subset=['preds'])\n",
    "    data = data.drop_duplicates(subset='original_title').loc[:, ['original_title', 'reviews_from_users', 'preds', 'preds_diff']]\n",
    "    data['preds'] = data['preds'].apply(lambda x: to_int(x))\n",
    "    data['reviews_from_users'] = data['reviews_from_users'].apply(lambda x: to_int(x))\n",
    "    data['preds_diff'] = data['preds'] - data['reviews_from_users']\n",
    "    data['preds_diff'] = data['preds_diff'].apply(np.absolute)\n",
    "    data = data.loc[(data['preds'] < 100) & (data['reviews_from_users'] < 100)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f35a2bf3-39f2-48ad-b8da-db1161cf3b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-20T23:36:12.932050Z",
     "iopub.status.busy": "2021-06-20T23:36:12.931326Z",
     "iopub.status.idle": "2021-06-20T23:36:13.284433Z",
     "shell.execute_reply": "2021-06-20T23:36:13.282573Z",
     "shell.execute_reply.started": "2021-06-20T23:36:12.931997Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średni bład dla 300 filmów z IMDB wynosi : 25.57\n"
     ]
    }
   ],
   "source": [
    "data = evaluate_model()\n",
    "print('Średni bład dla 300 filmów z IMDB wynosi :',  round(data['preds_diff'].mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2810f77-0081-4e17-a221-7f322c1b6069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
