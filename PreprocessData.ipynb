{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e501560f-da90-4ba9-bc9d-8c4684cd76fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:19:51.584573Z",
     "iopub.status.busy": "2021-06-17T18:19:51.584187Z",
     "iopub.status.idle": "2021-06-17T18:19:51.591421Z",
     "shell.execute_reply": "2021-06-17T18:19:51.590447Z",
     "shell.execute_reply.started": "2021-06-17T18:19:51.584535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_text as tf_text\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, InputLayer, GlobalMaxPool1D, Dropout, Conv1D, MaxPool1D, Flatten, Embedding, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b8a51a-3cc6-4bd3-b55a-c7f18cfce0c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.558029Z",
     "iopub.status.busy": "2021-06-17T18:17:03.557658Z",
     "iopub.status.idle": "2021-06-17T18:17:03.561917Z",
     "shell.execute_reply": "2021-06-17T18:17:03.561067Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.558004Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS \n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da2a9ae-d17d-403d-8d74-6778c6aece4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.563663Z",
     "iopub.status.busy": "2021-06-17T18:17:03.563378Z",
     "iopub.status.idle": "2021-06-17T18:17:03.568614Z",
     "shell.execute_reply": "2021-06-17T18:17:03.567841Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.563637Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def first_data_prep():\n",
    "    data = pd.read_csv('Data/twitter_data.csv', \n",
    "                      encoding='latin-1', names=['sentiment', 'id', 'date', 'flag', 'user',\n",
    "                                                'text'])\n",
    "    data['sentiment'].replace(4, 1, inplace=True)\n",
    "    data = data.sample(frac=1).reset_index(drop=True).copy()\n",
    "    data['text'] = data['text'].str.lower()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bcd13b7-0843-4b32-ad1a-b160ac329811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.570028Z",
     "iopub.status.busy": "2021-06-17T18:17:03.569762Z",
     "iopub.status.idle": "2021-06-17T18:17:03.574294Z",
     "shell.execute_reply": "2021-06-17T18:17:03.573434Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.570003Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delete_nicknames(row):\n",
    "    # Prepare list of words\n",
    "    words = row.split()\n",
    "    # Remove nicknames\n",
    "    for word in words:\n",
    "        if word[0] == '@':\n",
    "            words.remove(word)\n",
    "    # Return string \n",
    "    return ' '.join(word for word in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bdfc756-2ac8-49e5-8d79-f3c7387ba9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.575595Z",
     "iopub.status.busy": "2021-06-17T18:17:03.575322Z",
     "iopub.status.idle": "2021-06-17T18:17:03.580008Z",
     "shell.execute_reply": "2021-06-17T18:17:03.579151Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.575569Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stratified_split(df, size):\n",
    "    # Split dataset into smaller one \n",
    "    col_list = list(df.columns)\n",
    "    # Drop target column name\n",
    "    col_list.pop(0)\n",
    "    x_train, x_valid = train_test_split(\n",
    "    df, random_state=1, stratify=df['sentiment'], test_size=size)\n",
    "    # Prepare new indexes \n",
    "    x_valid.reset_index(drop=True, inplace=True)\n",
    "    return x_valid \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cda9969-ca0d-43a6-9f89-1342dcde9332",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.581276Z",
     "iopub.status.busy": "2021-06-17T18:17:03.581002Z",
     "iopub.status.idle": "2021-06-17T18:17:03.585907Z",
     "shell.execute_reply": "2021-06-17T18:17:03.585163Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.581237Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_with_space(text):\n",
    "    # Replace new rows with space \n",
    "    text = text.replace('\\n', \" \").replace(\"\\r\", \" \")\n",
    "    # Create list of all not needed chars \n",
    "    punc_list = '!\"@#$%^&*()+_-.<>?/:;[]{}|\\~'\n",
    "    # Make transformation with dict that contains punc_list chars\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    # Apply transformation\n",
    "    text = text.translate(t)\n",
    "    # Replace single quote with empty char\n",
    "    t = text.maketrans(dict.fromkeys(\"'`\"))\n",
    "    text.translate(t)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9cf7e8-aeb0-4998-b220-4ed427c348e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.587133Z",
     "iopub.status.busy": "2021-06-17T18:17:03.586876Z",
     "iopub.status.idle": "2021-06-17T18:17:03.591712Z",
     "shell.execute_reply": "2021-06-17T18:17:03.590872Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.587107Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    # Prepare set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Remove stopwords from the text\n",
    "    filtered_text = [word for word in text.split() if not word in stop_words]\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7a94e9-484f-468d-9576-2f1a35aa86bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:03.593547Z",
     "iopub.status.busy": "2021-06-17T18:17:03.593275Z",
     "iopub.status.idle": "2021-06-17T18:17:03.602270Z",
     "shell.execute_reply": "2021-06-17T18:17:03.600337Z",
     "shell.execute_reply.started": "2021-06-17T18:17:03.593521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(data, num_words, num_words_pad): \n",
    "    data = data.copy()\n",
    "    # Apply replace func that replace chars with spaces\n",
    "    data['text'] = data['text'].apply(lambda x: replace_with_space(x)).copy()\n",
    "    # Apply func that removes stop words\n",
    "    data['text'] = data['text'].apply(lambda x: remove_stop_words(x))\n",
    "    \n",
    "    # Initialize tokenizer\n",
    "    tok = tf.keras.preprocessing.text.Tokenizer(num_words=num_words)\n",
    "    # Updates internal vocabulary based on a list of texts \n",
    "    tok.fit_on_texts(list(data['text']))\n",
    "    # Transforms each text in texts to a sequence of integers.\n",
    "    seq = tok.texts_to_sequences(list(data['text']))\n",
    "    # Pad sequences to make them same lenght \n",
    "    tf_ready = tf.keras.preprocessing.sequence.pad_sequences(seq)\n",
    "    \n",
    "    return tf_ready, tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b76cd1-e239-460d-afc8-117376c6d559",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:17:39.054606Z",
     "iopub.status.busy": "2021-06-17T18:17:39.053916Z",
     "iopub.status.idle": "2021-06-17T18:19:51.582416Z",
     "shell.execute_reply": "2021-06-17T18:19:51.581127Z",
     "shell.execute_reply.started": "2021-06-17T18:17:39.054539Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-19089cd62480>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['text'].apply(lambda x: replace_with_space(x)).copy()\n",
      "<ipython-input-11-19089cd62480>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text'] = data['text'].apply(lambda x: remove_stop_words(x))\n"
     ]
    }
   ],
   "source": [
    "data1 = first_data_prep()\n",
    "data = stratified_split(data1, 0.5)\n",
    "# Apply replace func that replace chars with spaces\n",
    "data['text'] = data['text'].apply(lambda x: replace_with_space(x)).copy()\n",
    "# Apply func that removes stop words\n",
    "data['text'] = data['text'].apply(lambda x: remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b4e9805-4e45-4718-97bd-8480b90c108f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:19:58.561667Z",
     "iopub.status.busy": "2021-06-17T18:19:58.561164Z",
     "iopub.status.idle": "2021-06-17T18:20:01.048324Z",
     "shell.execute_reply": "2021-06-17T18:20:01.047651Z",
     "shell.execute_reply.started": "2021-06-17T18:19:58.561619Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(vector_size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)\n",
    "    \n",
    "documents = data.text\n",
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "427cb6db-41c4-412f-bade-a158536ce919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:20:10.944127Z",
     "iopub.status.busy": "2021-06-17T18:20:10.942677Z",
     "iopub.status.idle": "2021-06-17T18:20:24.871204Z",
     "shell.execute_reply": "2021-06-17T18:20:24.870588Z",
     "shell.execute_reply.started": "2021-06-17T18:20:10.943990Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tok = tf.keras.preprocessing.text.Tokenizer(num_words=100000)\n",
    "# Updates internal vocabulary based on a list of texts \n",
    "tok.fit_on_texts(list(data['text']))\n",
    "# Transforms each text in texts to a sequence of integers.\n",
    "seq = tok.texts_to_sequences(list(data['text']))\n",
    "# Pad sequences to make them same lenght \n",
    "tf_ready = tf.keras.preprocessing.sequence.pad_sequences(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1f96670-c18b-4736-b2f2-f3b7bcc9cfd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T20:01:03.981470Z",
     "iopub.status.busy": "2021-06-17T20:01:03.980934Z",
     "iopub.status.idle": "2021-06-17T20:01:04.499395Z",
     "shell.execute_reply": "2021-06-17T20:01:04.498548Z",
     "shell.execute_reply.started": "2021-06-17T20:01:03.981400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('tok.pkl', 'wb') as f:\n",
    "    pickle.dump(tok, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e00fa934-b6fb-40e1-8d57-50eb98268783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:20:39.901582Z",
     "iopub.status.busy": "2021-06-17T18:20:39.901014Z",
     "iopub.status.idle": "2021-06-17T18:20:39.909566Z",
     "shell.execute_reply": "2021-06-17T18:20:39.907819Z",
     "shell.execute_reply.started": "2021-06-17T18:20:39.901528Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 461914\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.index_to_key\n",
    "vocab_size = len(tok.word_index) + 1\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ed6087b-3742-4281-aa3b-6857d91518f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:20:45.808783Z",
     "iopub.status.busy": "2021-06-17T18:20:45.808178Z",
     "iopub.status.idle": "2021-06-17T18:25:26.718677Z",
     "shell.execute_reply": "2021-06-17T18:25:26.717272Z",
     "shell.execute_reply.started": "2021-06-17T18:20:45.808728Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173611450, 207869408)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a09d4c-33f1-40af-90fb-92fda1b2dc3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:25:41.585610Z",
     "iopub.status.busy": "2021-06-17T18:25:41.585319Z",
     "iopub.status.idle": "2021-06-17T18:25:42.069754Z",
     "shell.execute_reply": "2021-06-17T18:25:42.067396Z",
     "shell.execute_reply.started": "2021-06-17T18:25:41.585584Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tok.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "embedding_layer = Embedding(vocab_size, W2V_SIZE,\n",
    "                            weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28bd2eba-52be-4224-9bc5-c0287baec262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:26:16.925678Z",
     "iopub.status.busy": "2021-06-17T18:26:16.924227Z",
     "iopub.status.idle": "2021-06-17T18:26:21.747832Z",
     "shell.execute_reply": "2021-06-17T18:26:21.747080Z",
     "shell.execute_reply.started": "2021-06-17T18:26:16.925539Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('embedding.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_layer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3465d0-75c6-4d89-b009-152411685208",
   "metadata": {},
   "source": [
    "data = first_data_prep()\n",
    "split_data= stratified_split(data, 0.1)\n",
    "tf_ready, tok = tokenize(split_data, 10000, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19f6f475-754a-4a5d-befa-afe190c7ca6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:26:47.577058Z",
     "iopub.status.busy": "2021-06-17T18:26:47.576735Z",
     "iopub.status.idle": "2021-06-17T18:26:48.087618Z",
     "shell.execute_reply": "2021-06-17T18:26:48.085010Z",
     "shell.execute_reply.started": "2021-06-17T18:26:47.577031Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame(tf_ready)\n",
    "tf_df['sentiment'] = data['sentiment']\n",
    "with open('tf_df.pkl', 'wb') as f:\n",
    "    pickle.dump(tf_df, f)\n",
    "# tf_df.to_csv('tokenized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9231c5e3-8e3a-4d12-82cc-77a522af74d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:26:52.066466Z",
     "iopub.status.busy": "2021-06-17T18:26:52.066150Z",
     "iopub.status.idle": "2021-06-17T18:26:52.076001Z",
     "shell.execute_reply": "2021-06-17T18:26:52.074852Z",
     "shell.execute_reply.started": "2021-06-17T18:26:52.066439Z"
    }
   },
   "outputs": [],
   "source": [
    "def configure_cnn(data,\n",
    "                embedding,\n",
    "                layers=None, \n",
    "                dropout_rate=0,\n",
    "                kernel_size=10,\n",
    "                stride=10,\n",
    "                pool_size=2,\n",
    "                optimizer='Adam',\n",
    "                loss='binary_crossentropy',\n",
    "                 kernel_initializer='lecun_normal',\n",
    "                 kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "                ):\n",
    "    \"\"\" Layers argument shape:\n",
    "    [[number of nodes, activate function], \n",
    "    [number of nodes, activate function],\n",
    "    ...]\n",
    "    \n",
    "    \"\"\"\n",
    "    input_len = data.shape[1] - 1 \n",
    "    model = Sequential()\n",
    "    model.add(embedding)\n",
    "    model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
    "    model.add(MaxPool1D(3))\n",
    "    model.add(Conv1D(64, 3, activation='relu'))\n",
    "    model.add(MaxPool1D(pool_size=3))\n",
    "    model.add(Conv1D(128, 3, activation='relu'))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    if dropout_rate > 0:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    if layers != None:\n",
    "        for node in layers[1:]:\n",
    "            model.add(Dense(node[0], activation=node[1], kernel_initializer=kernel_initializer, \n",
    "                            kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Dense(10, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, \n",
    "                    kernel_regularizer=kernel_regularizer))\n",
    "    \n",
    "    model.compile(loss=loss, \n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7c6a7a4-0408-43f8-a578-f64a7596ef81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:26:52.701530Z",
     "iopub.status.busy": "2021-06-17T18:26:52.700788Z",
     "iopub.status.idle": "2021-06-17T18:26:52.713191Z",
     "shell.execute_reply": "2021-06-17T18:26:52.711981Z",
     "shell.execute_reply.started": "2021-06-17T18:26:52.701474Z"
    }
   },
   "outputs": [],
   "source": [
    "def configure_rnn(data,\n",
    "                embedding,\n",
    "                layers=None, \n",
    "                dropout_rate=0,\n",
    "                kernel_size=10,\n",
    "                stride=10,\n",
    "                pool_size=2,\n",
    "                optimizer='Adam',\n",
    "                loss='binary_crossentropy',\n",
    "                 kernel_initializer='lecun_normal',\n",
    "                 kernel_regularizer=tf.keras.regularizers.L2(0.01)\n",
    "                ):\n",
    "    \"\"\" Layers argument shape:\n",
    "    [[number of nodes, activate function], \n",
    "    [number of nodes, activate function],\n",
    "    ...]\n",
    "    \n",
    "    \"\"\"\n",
    "    input_len = data.shape[1] - 1 \n",
    "    model = Sequential()\n",
    "    model.add(embedding)\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))    \n",
    "\n",
    "    if layers != None:\n",
    "        for node in layers[1:]:\n",
    "            model.add(Dense(node[0], activation=node[1], kernel_initializer=kernel_initializer, \n",
    "                            kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, \n",
    "                    kernel_regularizer=kernel_regularizer))\n",
    "    \n",
    "    model.compile(loss=loss, \n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a2dc25a-9ada-4e71-81f9-f0a95d56de7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:26:54.601546Z",
     "iopub.status.busy": "2021-06-17T18:26:54.601049Z",
     "iopub.status.idle": "2021-06-17T18:26:56.172527Z",
     "shell.execute_reply": "2021-06-17T18:26:56.171814Z",
     "shell.execute_reply.started": "2021-06-17T18:26:54.601502Z"
    }
   },
   "outputs": [],
   "source": [
    "model = configure_cnn(tf_df, embedding_layer)\n",
    "model_rnn = configure_rnn(tf_df, embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2648268-6ef0-42bd-b48d-e46301c18b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:27:08.079019Z",
     "iopub.status.busy": "2021-06-17T18:27:08.078704Z",
     "iopub.status.idle": "2021-06-17T18:27:08.311098Z",
     "shell.execute_reply": "2021-06-17T18:27:08.310094Z",
     "shell.execute_reply.started": "2021-06-17T18:27:08.078992Z"
    }
   },
   "outputs": [],
   "source": [
    "features = tf_df.columns.tolist()\n",
    "features.remove('sentiment')\n",
    "X_train, X_test, y_train, y_test = train_test_split(tf_df[features], tf_df['sentiment'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0686d7b-3c49-4c52-adf2-08005a28fea9",
   "metadata": {},
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "201f3d48-f00c-4761-a7ad-36a25d277787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:27:00.526106Z",
     "iopub.status.busy": "2021-06-17T18:27:00.525828Z",
     "iopub.status.idle": "2021-06-17T18:27:00.537749Z",
     "shell.execute_reply": "2021-06-17T18:27:00.536800Z",
     "shell.execute_reply.started": "2021-06-17T18:27:00.526081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          138574200 \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 300, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 30, 128)           24704     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 138,635,245\n",
      "Trainable params: 61,045\n",
      "Non-trainable params: 138,574,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2eff5d4-e725-4a75-92dc-75761d9e616b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:27:03.003085Z",
     "iopub.status.busy": "2021-06-17T18:27:03.001931Z",
     "iopub.status.idle": "2021-06-17T18:27:03.020947Z",
     "shell.execute_reply": "2021-06-17T18:27:03.019953Z",
     "shell.execute_reply.started": "2021-06-17T18:27:03.002992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          138574200 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 138,734,701\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 138,574,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434b941d-575a-4cfe-be12-27df523677c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=EPOCHS, verbose=1,\n",
    "         validation_data=(X_test, y_test), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cba050-8fb9-43bd-8d9a-8803f4d95f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a40f6c03-41d5-4775-b454-f1d85b5ee012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T18:27:18.473119Z",
     "iopub.status.busy": "2021-06-17T18:27:18.472803Z",
     "iopub.status.idle": "2021-06-17T19:36:32.013144Z",
     "shell.execute_reply": "2021-06-17T19:36:32.011988Z",
     "shell.execute_reply.started": "2021-06-17T18:27:18.473088Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "524/524 [==============================] - ETA: 0s - loss: 0.5563 - accuracy: 0.7180WARNING:tensorflow:Model was constructed with shape (None, 300) for input KerasTensor(type_spec=TensorSpec(shape=(None, 300), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "524/524 [==============================] - 520s 990ms/step - loss: 0.5563 - accuracy: 0.7181 - val_loss: 0.4796 - val_accuracy: 0.7726\n",
      "Epoch 2/8\n",
      "524/524 [==============================] - 519s 991ms/step - loss: 0.4991 - accuracy: 0.7592 - val_loss: 0.4727 - val_accuracy: 0.7778\n",
      "Epoch 3/8\n",
      "524/524 [==============================] - 520s 993ms/step - loss: 0.4886 - accuracy: 0.7665 - val_loss: 0.4649 - val_accuracy: 0.7829\n",
      "Epoch 4/8\n",
      "524/524 [==============================] - 519s 990ms/step - loss: 0.4818 - accuracy: 0.7701 - val_loss: 0.4647 - val_accuracy: 0.7841\n",
      "Epoch 5/8\n",
      "524/524 [==============================] - 517s 987ms/step - loss: 0.4786 - accuracy: 0.7728 - val_loss: 0.4645 - val_accuracy: 0.7841\n",
      "Epoch 6/8\n",
      "524/524 [==============================] - 518s 990ms/step - loss: 0.4762 - accuracy: 0.7733 - val_loss: 0.4586 - val_accuracy: 0.7867\n",
      "Epoch 7/8\n",
      "524/524 [==============================] - 520s 992ms/step - loss: 0.4736 - accuracy: 0.7759 - val_loss: 0.4588 - val_accuracy: 0.7873\n",
      "Epoch 8/8\n",
      "524/524 [==============================] - 519s 991ms/step - loss: 0.4723 - accuracy: 0.7763 - val_loss: 0.4580 - val_accuracy: 0.7887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f14df780fa0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train, epochs=EPOCHS, verbose=1,\n",
    "         validation_data=(X_test, y_test), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "161157e0-6775-4415-b814-2de413be67c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-17T19:36:32.015581Z",
     "iopub.status.busy": "2021-06-17T19:36:32.015146Z",
     "iopub.status.idle": "2021-06-17T19:36:43.344731Z",
     "shell.execute_reply": "2021-06-17T19:36:43.341604Z",
     "shell.execute_reply.started": "2021-06-17T19:36:32.015539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: rnn/assets\n"
     ]
    }
   ],
   "source": [
    "model_rnn.save('rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f22cda-7d07-4daa-9bb6-bf7b1c24eac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a4c67-35f8-44cf-abc5-434a0a8ad651",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn')\n",
    "model_rnn.save('rnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "04965c36-95a7-46fd-a9cb-49d354337080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [@elleasinswell, oh,, i'll, have, to, try, it!...\n",
       "1          [@cmlundy, done!!!!!, i, really, need, one, to...\n",
       "2          [lost, google, notebook, ie, add, on, with, th...\n",
       "3          [@natalietran, at, least, they, have, a, moral...\n",
       "4          [@kirstyhilton, ive, been, trying, to, get, mi...\n",
       "                                 ...                        \n",
       "1599995    [ain't, watching, the, laker, game,, i, can't,...\n",
       "1599996    [bummed, about, the, softball, loss, 0-1, thes...\n",
       "1599997    [back, in, god's, hands,, back, in, god's, han...\n",
       "1599998                                         [bbq, party]\n",
       "1599999    [@iamjemzie, what, time, is, this, and, where,...\n",
       "Name: text, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.77\n",
    "ef strip(row):\n",
    "    return row.split()\n",
    "\n",
    "data['text'].apply(lambda x: strip(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7dd931c-24e8-429f-9bb8-24554e091f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78053a6b-8142-4091-8562-019c4279c695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@cmlundy done!!!!! i really need one too... aritzia hasnt gotten back yet  dammit!!'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd00c7d-54f2-4c45-8e06-daeb4de9a4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
